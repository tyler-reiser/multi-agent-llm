{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright, let’s initialize our Rust backend with Axum and get our API up and running.\n",
    "\n",
    "🛠 Step 1: Set Up the Project\n",
    "\n",
    "First, make sure you have Rust & Cargo installed. If not, install Rust using:\n",
    "\n",
    "curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh\n",
    "\n",
    "Then, create a new Rust project:\n",
    "\n",
    "cargo new llm-playground-backend --bin\n",
    "cd llm-playground-backend\n",
    "\n",
    "🛠 Step 2: Add Dependencies\n",
    "\n",
    "Edit Cargo.toml and add the required crates:\n",
    "\n",
    "[dependencies]\n",
    "axum = \"0.6\"\n",
    "tokio = { version = \"1\", features = [\"full\"] }\n",
    "serde = { version = \"1\", features = [\"derive\"] }\n",
    "serde_json = \"1\"\n",
    "tower = \"0.4\"\n",
    "tower-http = { version = \"0.3\", features = [\"cors\", \"trace\"] }\n",
    "jsonwebtoken = \"8\"\n",
    "sqlx = { version = \"0.6\", features = [\"postgres\", \"runtime-tokio-native-tls\"] }\n",
    "dotenvy = \"0.15\"\n",
    "\n",
    "Then, install them with:\n",
    "\n",
    "cargo build\n",
    "\n",
    "🛠 Step 3: Create Main Entry Point\n",
    "\n",
    "Modify src/main.rs:\n",
    "\n",
    "use axum::{routing::get, Router};\n",
    "use std::net::SocketAddr;\n",
    "use tower_http::cors::{CorsLayer, Any};\n",
    "\n",
    "#[tokio::main]\n",
    "async fn main() {\n",
    "    let app = Router::new()\n",
    "        .route(\"/\", get(root))\n",
    "        .layer(CorsLayer::new().allow_origin(Any));\n",
    "\n",
    "    let addr = SocketAddr::from(([127, 0, 0, 1], 3000));\n",
    "    println!(\"🚀 Server running at http://{}\", addr);\n",
    "\n",
    "    axum::Server::bind(&addr)\n",
    "        .serve(app.into_make_service())\n",
    "        .await\n",
    "        .unwrap();\n",
    "}\n",
    "\n",
    "async fn root() -> &'static str {\n",
    "    \"Hello, Rust with Axum!\"\n",
    "}\n",
    "\n",
    "🛠 Step 4: Run the Server\n",
    "\n",
    "Now, start the backend:\n",
    "\n",
    "cargo run\n",
    "\n",
    "You should see:\n",
    "\n",
    "🚀 Server running at http://127.0.0.1:3000\n",
    "\n",
    "Visit http://127.0.0.1:3000 in your browser, and it should return:\n",
    "\n",
    "Hello, Rust with Axum!\n",
    "\n",
    "🔗 Next Steps\n",
    "\n",
    "1️⃣ Set up database connection (PostgreSQL + SQLx).\n",
    "2️⃣ Add authentication (JWT-based auth).\n",
    "3️⃣ Implement AI API routing (OpenAI calls).\n",
    "4️⃣ Build the AI chat and blogging endpoints.\n",
    "\n",
    "And just like that, our Rust backend is alive. Ready for the next move? 🚀"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes! Database setup is the next critical step so we can store chat history, user data, and blog posts. Let’s get it done. 🚀\n",
    "\n",
    "🛠 Step 1: Configure Environment Variables\n",
    "\n",
    "First, we create a .env file in the project root to store database credentials securely.\n",
    "\n",
    "touch .env\n",
    "\n",
    "Inside .env, add:\n",
    "\n",
    "DATABASE_URL=postgres://username:password@localhost/llm_playground\n",
    "\n",
    "Replace username, password, and llm_playground with your actual PostgreSQL credentials.\n",
    "\n",
    "Also, add .env to .gitignore to prevent committing secrets:\n",
    "\n",
    "echo \".env\" >> .gitignore\n",
    "\n",
    "🛠 Step 2: Install & Configure SQLx\n",
    "\n",
    "Since we’re using PostgreSQL, install sqlx CLI and migrations support:\n",
    "\n",
    "cargo install sqlx-cli --no-default-features --features postgres\n",
    "\n",
    "Then, install sqlx in the project dependencies (already in our Cargo.toml but ensure it’s there):\n",
    "\n",
    "[dependencies]\n",
    "sqlx = { version = \"0.6\", features = [\"postgres\", \"runtime-tokio-native-tls\"] }\n",
    "\n",
    "🛠 Step 3: Create the Database\n",
    "\n",
    "If PostgreSQL isn’t running yet, start it:\n",
    "\n",
    "sudo service postgresql start  # Linux/macOS\n",
    "pg_ctl -D /usr/local/var/postgres start  # Homebrew (Mac)\n",
    "\n",
    "Then, create the database:\n",
    "\n",
    "psql -U username -c \"CREATE DATABASE llm_playground;\"\n",
    "\n",
    "🛠 Step 4: Create Database Migrations\n",
    "\n",
    "Run:\n",
    "\n",
    "sqlx migrate add init\n",
    "\n",
    "This will create a migrations/ directory with a new SQL file. Edit it to include our schema:\n",
    "\n",
    "-- migrations/YYYYMMDDHHMMSS_init.sql\n",
    "\n",
    "-- Users table\n",
    "CREATE TABLE users (\n",
    "    id SERIAL PRIMARY KEY,\n",
    "    username TEXT NOT NULL UNIQUE,\n",
    "    email TEXT NOT NULL UNIQUE,\n",
    "    password_hash TEXT NOT NULL,\n",
    "    created_at TIMESTAMP DEFAULT now()\n",
    ");\n",
    "\n",
    "-- Chat history table\n",
    "CREATE TABLE chats (\n",
    "    id SERIAL PRIMARY KEY,\n",
    "    user_id INTEGER REFERENCES users(id) ON DELETE CASCADE,\n",
    "    message TEXT NOT NULL,\n",
    "    response TEXT NOT NULL,\n",
    "    created_at TIMESTAMP DEFAULT now()\n",
    ");\n",
    "\n",
    "-- Blog posts table\n",
    "CREATE TABLE blogs (\n",
    "    id SERIAL PRIMARY KEY,\n",
    "    user_id INTEGER REFERENCES users(id) ON DELETE CASCADE,\n",
    "    title TEXT NOT NULL,\n",
    "    content TEXT NOT NULL,\n",
    "    created_at TIMESTAMP DEFAULT now()\n",
    ");\n",
    "\n",
    "Apply the migration:\n",
    "\n",
    "sqlx migrate run\n",
    "\n",
    "🛠 Step 5: Connect Axum to PostgreSQL in Rust\n",
    "\n",
    "Modify src/main.rs:\n",
    "\n",
    "use axum::{Router, routing::get};\n",
    "use sqlx::{PgPool, postgres::PgPoolOptions};\n",
    "use std::env;\n",
    "use tower_http::cors::{CorsLayer, Any};\n",
    "\n",
    "#[tokio::main]\n",
    "async fn main() {\n",
    "    dotenvy::dotenv().ok(); // Load .env file\n",
    "\n",
    "    // Connect to database\n",
    "    let database_url = env::var(\"DATABASE_URL\").expect(\"DATABASE_URL must be set\");\n",
    "    let pool = PgPoolOptions::new()\n",
    "        .max_connections(5)\n",
    "        .connect(&database_url)\n",
    "        .await\n",
    "        .expect(\"Failed to connect to database\");\n",
    "\n",
    "    let app = Router::new()\n",
    "        .route(\"/\", get(|| async { \"Hello, database is connected!\" }))\n",
    "        .layer(CorsLayer::new().allow_origin(Any()));\n",
    "\n",
    "    println!(\"🚀 Server running at http://127.0.0.1:3000\");\n",
    "\n",
    "    axum::Server::bind(&\"127.0.0.1:3000\".parse().unwrap())\n",
    "        .serve(app.into_make_service())\n",
    "        .await\n",
    "        .unwrap();\n",
    "}\n",
    "\n",
    "🛠 Step 6: Test Database Connection\n",
    "\n",
    "Run the server again:\n",
    "\n",
    "cargo run\n",
    "\n",
    "If successful, you’ll see:\n",
    "\n",
    "🚀 Server running at http://127.0.0.1:3000\n",
    "\n",
    "Now we’re fully connected to PostgreSQL! 🎉\n",
    "\n",
    "🔜 Next Steps\n",
    "\n",
    "1️⃣ Implement user authentication (hash passwords, JWT auth).\n",
    "2️⃣ Create API routes for chat & blog storage.\n",
    "3️⃣ Build AI model routing layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome! Now, let’s implement authentication so users can register, log in, and securely access routes. We’ll use JWT (JSON Web Tokens) for authentication and argon2 for password hashing.\n",
    "\n",
    "🛠 Step 1: Install Dependencies\n",
    "\n",
    "We need libraries for authentication, hashing, and token handling. Add these to Cargo.toml:\n",
    "\n",
    "[dependencies]\n",
    "jsonwebtoken = \"8\"\n",
    "argon2 = \"0.5\"\n",
    "rand = \"0.8\"\n",
    "axum-extra = { version = \"0.8\", features = [\"typed-header\"] }\n",
    "\n",
    "Then, install them:\n",
    "\n",
    "cargo build\n",
    "\n",
    "🛠 Step 2: Update Database for Authentication\n",
    "\n",
    "We already created a users table in our database. Now, ensure it’s properly set up for hashed passwords.\n",
    "\n",
    "If needed, modify the migrations/init.sql and re-run:\n",
    "\n",
    "sqlx migrate run\n",
    "\n",
    "🛠 Step 3: Create Authentication Utilities\n",
    "\n",
    "Inside src/auth.rs, add:\n",
    "\n",
    "use argon2::{Argon2, PasswordHash, PasswordHasher, PasswordVerifier};\n",
    "use jsonwebtoken::{encode, decode, Header, Validation, EncodingKey, DecodingKey};\n",
    "use rand::rngs::OsRng;\n",
    "use serde::{Deserialize, Serialize};\n",
    "use std::env;\n",
    "\n",
    "// Secret key for JWT\n",
    "const SECRET_KEY: &str = \"supersecretkey\"; // Change this in production\n",
    "\n",
    "// Structure for JWT claims\n",
    "#[derive(Debug, Serialize, Deserialize)]\n",
    "struct Claims {\n",
    "    sub: String,  // User ID\n",
    "    exp: usize,   // Expiry timestamp\n",
    "}\n",
    "\n",
    "// Hash a password\n",
    "pub fn hash_password(password: &str) -> String {\n",
    "    let salt = rand::thread_rng();\n",
    "    let argon2 = Argon2::default();\n",
    "    argon2.hash_password(password.as_bytes(), &salt)\n",
    "        .expect(\"Password hashing failed\")\n",
    "        .to_string()\n",
    "}\n",
    "\n",
    "// Verify a password\n",
    "pub fn verify_password(password: &str, hash: &str) -> bool {\n",
    "    let parsed_hash = PasswordHash::new(hash).expect(\"Invalid password hash\");\n",
    "    Argon2::default().verify_password(password.as_bytes(), &parsed_hash).is_ok()\n",
    "}\n",
    "\n",
    "// Generate JWT token\n",
    "pub fn generate_jwt(user_id: &str) -> String {\n",
    "    let expiration = chrono::Utc::now() + chrono::Duration::hours(24);\n",
    "    let claims = Claims {\n",
    "        sub: user_id.to_owned(),\n",
    "        exp: expiration.timestamp() as usize,\n",
    "    };\n",
    "\n",
    "    encode(&Header::default(), &claims, &EncodingKey::from_secret(SECRET_KEY.as_ref()))\n",
    "        .expect(\"Token generation failed\")\n",
    "}\n",
    "\n",
    "// Validate JWT token\n",
    "pub fn validate_jwt(token: &str) -> Option<String> {\n",
    "    decode::<Claims>(token, &DecodingKey::from_secret(SECRET_KEY.as_ref()), &Validation::default())\n",
    "        .ok()\n",
    "        .map(|data| data.claims.sub)\n",
    "}\n",
    "\n",
    "🛠 Step 4: Create Auth Routes\n",
    "\n",
    "Inside src/routes/auth.rs:\n",
    "\n",
    "use axum::{Json, Router, extract::State, routing::post};\n",
    "use serde::{Deserialize, Serialize};\n",
    "use sqlx::PgPool;\n",
    "\n",
    "use crate::auth::{hash_password, verify_password, generate_jwt};\n",
    "\n",
    "#[derive(Deserialize)]\n",
    "struct RegisterUser {\n",
    "    username: String,\n",
    "    email: String,\n",
    "    password: String,\n",
    "}\n",
    "\n",
    "#[derive(Deserialize)]\n",
    "struct LoginUser {\n",
    "    email: String,\n",
    "    password: String,\n",
    "}\n",
    "\n",
    "#[derive(Serialize)]\n",
    "struct AuthResponse {\n",
    "    token: String,\n",
    "}\n",
    "\n",
    "// Register route\n",
    "async fn register(State(pool): State<PgPool>, Json(payload): Json<RegisterUser>) -> Json<AuthResponse> {\n",
    "    let hashed_password = hash_password(&payload.password);\n",
    "    \n",
    "    let _ = sqlx::query!(\n",
    "        \"INSERT INTO users (username, email, password_hash) VALUES ($1, $2, $3)\",\n",
    "        payload.username,\n",
    "        payload.email,\n",
    "        hashed_password,\n",
    "    )\n",
    "    .execute(&pool)\n",
    "    .await\n",
    "    .expect(\"Failed to insert user\");\n",
    "\n",
    "    let token = generate_jwt(&payload.email);\n",
    "    Json(AuthResponse { token })\n",
    "}\n",
    "\n",
    "// Login route\n",
    "async fn login(State(pool): State<PgPool>, Json(payload): Json<LoginUser>) -> Json<AuthResponse> {\n",
    "    let user = sqlx::query!(\n",
    "        \"SELECT password_hash FROM users WHERE email = $1\",\n",
    "        payload.email,\n",
    "    )\n",
    "    .fetch_one(&pool)\n",
    "    .await\n",
    "    .expect(\"User not found\");\n",
    "\n",
    "    if verify_password(&payload.password, &user.password_hash) {\n",
    "        let token = generate_jwt(&payload.email);\n",
    "        Json(AuthResponse { token })\n",
    "    } else {\n",
    "        panic!(\"Invalid credentials\")\n",
    "    }\n",
    "}\n",
    "\n",
    "// Create authentication router\n",
    "pub fn auth_routes(pool: PgPool) -> Router {\n",
    "    Router::new()\n",
    "        .route(\"/register\", post(register))\n",
    "        .route(\"/login\", post(login))\n",
    "        .with_state(pool)\n",
    "}\n",
    "\n",
    "🛠 Step 5: Add Auth Routes to main.rs\n",
    "\n",
    "Modify src/main.rs to include authentication:\n",
    "\n",
    "mod auth;\n",
    "mod routes;\n",
    "\n",
    "use axum::{Router, routing::get};\n",
    "use sqlx::PgPool;\n",
    "use std::env;\n",
    "use tower_http::cors::{CorsLayer, Any};\n",
    "use routes::auth::auth_routes;\n",
    "\n",
    "#[tokio::main]\n",
    "async fn main() {\n",
    "    dotenvy::dotenv().ok();\n",
    "\n",
    "    let database_url = env::var(\"DATABASE_URL\").expect(\"DATABASE_URL must be set\");\n",
    "    let pool = PgPool::connect(&database_url).await.expect(\"Failed to connect to database\");\n",
    "\n",
    "    let app = Router::new()\n",
    "        .route(\"/\", get(|| async { \"Welcome to the API!\" }))\n",
    "        .merge(auth_routes(pool.clone()))\n",
    "        .layer(CorsLayer::new().allow_origin(Any()));\n",
    "\n",
    "    println!(\"🚀 Server running at http://127.0.0.1:3000\");\n",
    "\n",
    "    axum::Server::bind(&\"127.0.0.1:3000\".parse().unwrap())\n",
    "        .serve(app.into_make_service())\n",
    "        .await\n",
    "        .unwrap();\n",
    "}\n",
    "\n",
    "🛠 Step 6: Test Authentication\n",
    "\n",
    "1️⃣ Run the server:\n",
    "\n",
    "cargo run\n",
    "\n",
    "2️⃣ Register a new user:\n",
    "\n",
    "curl -X POST http://127.0.0.1:3000/register \\\n",
    "     -H \"Content-Type: application/json\" \\\n",
    "     -d '{ \"username\": \"testuser\", \"email\": \"test@example.com\", \"password\": \"password123\" }'\n",
    "\n",
    "💡 Response should contain a JWT token!\n",
    "\n",
    "3️⃣ Login with the user:\n",
    "\n",
    "curl -X POST http://127.0.0.1:3000/login \\\n",
    "     -H \"Content-Type: application/json\" \\\n",
    "     -d '{ \"email\": \"test@example.com\", \"password\": \"password123\" }'\n",
    "\n",
    "💡 Should return a JWT token if credentials are correct.\n",
    "\n",
    "🔜 Next Steps\n",
    "\n",
    "1️⃣ Secure routes with JWT middleware (restrict access to authenticated users).\n",
    "2️⃣ Store AI chat history linked to users.\n",
    "3️⃣ Implement AI model selection API.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great choice! Securing the routes ensures that only authenticated users can access chat history, AI interactions, and blog storage. Let’s build JWT authentication middleware to enforce security on protected routes.\n",
    "\n",
    "🛠 Step 1: Create JWT Authentication Middleware\n",
    "\n",
    "1️⃣ Create a New File for Authentication Middleware\n",
    "\n",
    "Inside src/middleware.rs, add:\n",
    "\n",
    "use axum::{\n",
    "    http::{Request, StatusCode},\n",
    "    middleware::Next,\n",
    "    response::{IntoResponse, Response},\n",
    "    TypedHeader, RequestPartsExt,\n",
    "};\n",
    "use axum_extra::headers::Authorization;\n",
    "use crate::auth::validate_jwt;\n",
    "\n",
    "// Middleware function to verify JWT\n",
    "pub async fn auth_middleware<B>(req: Request<B>, next: Next<B>) -> Result<Response, StatusCode> {\n",
    "    // Extract Authorization header\n",
    "    let auth_header = req\n",
    "        .headers()\n",
    "        .get(\"Authorization\")\n",
    "        .and_then(|hv| hv.to_str().ok());\n",
    "\n",
    "    // Ensure the token is present and valid\n",
    "    if let Some(token) = auth_header.and_then(|h| h.strip_prefix(\"Bearer \")) {\n",
    "        if let Some(user_id) = validate_jwt(token) {\n",
    "            // Store user ID in request extensions for use in handlers\n",
    "            let mut req = req;\n",
    "            req.extensions_mut().insert(user_id);\n",
    "            return Ok(next.run(req).await);\n",
    "        }\n",
    "    }\n",
    "\n",
    "    // Unauthorized response if JWT is missing or invalid\n",
    "    Err(StatusCode::UNAUTHORIZED)\n",
    "}\n",
    "\n",
    "🔹 This extracts the JWT token from the Authorization header,\n",
    "🔹 Validates the token,\n",
    "🔹 Injects user ID into the request, so handlers can access it.\n",
    "\n",
    "🛠 Step 2: Modify main.rs to Use Middleware\n",
    "\n",
    "Now, import and apply this middleware to protected routes in src/main.rs:\n",
    "\n",
    "mod auth;\n",
    "mod middleware;\n",
    "mod routes;\n",
    "\n",
    "use axum::{Router, routing::get, middleware::from_fn};\n",
    "use sqlx::PgPool;\n",
    "use std::env;\n",
    "use tower_http::cors::{CorsLayer, Any};\n",
    "use routes::auth::auth_routes;\n",
    "use middleware::auth_middleware;\n",
    "\n",
    "#[tokio::main]\n",
    "async fn main() {\n",
    "    dotenvy::dotenv().ok();\n",
    "\n",
    "    let database_url = env::var(\"DATABASE_URL\").expect(\"DATABASE_URL must be set\");\n",
    "    let pool = PgPool::connect(&database_url).await.expect(\"Failed to connect to database\");\n",
    "\n",
    "    let app = Router::new()\n",
    "        .route(\"/\", get(|| async { \"Welcome to the API!\" }))\n",
    "        .merge(auth_routes(pool.clone()))\n",
    "        // Protect all /chat and /blog routes\n",
    "        .route_layer(from_fn(auth_middleware))\n",
    "        .layer(CorsLayer::new().allow_origin(Any()));\n",
    "\n",
    "    println!(\"🚀 Server running at http://127.0.0.1:3000\");\n",
    "\n",
    "    axum::Server::bind(&\"127.0.0.1:3000\".parse().unwrap())\n",
    "        .serve(app.into_make_service())\n",
    "        .await\n",
    "        .unwrap();\n",
    "}\n",
    "\n",
    "🔹 route_layer(from_fn(auth_middleware)) ensures only authenticated users can access /chat and /blog.\n",
    "🔹 Public routes (like /register and /login) don’t need authentication.\n",
    "\n",
    "🛠 Step 3: Modify auth.rs to Extract User ID in Handlers\n",
    "\n",
    "Since we inject user ID into requests, let’s modify our handlers to use it.\n",
    "\n",
    "Inside src/routes/chat.rs, add:\n",
    "\n",
    "use axum::{extract::State, http::StatusCode, Json, Extension};\n",
    "use serde::{Deserialize, Serialize};\n",
    "use sqlx::PgPool;\n",
    "\n",
    "#[derive(Deserialize)]\n",
    "struct ChatMessage {\n",
    "    message: String,\n",
    "}\n",
    "\n",
    "#[derive(Serialize)]\n",
    "struct ChatResponse {\n",
    "    response: String,\n",
    "}\n",
    "\n",
    "// Protected chat route\n",
    "async fn chat_handler(\n",
    "    Extension(user_id): Extension<String>,  // Extract user ID from request\n",
    "    State(pool): State<PgPool>,\n",
    "    Json(payload): Json<ChatMessage>,\n",
    ") -> Result<Json<ChatResponse>, StatusCode> {\n",
    "    \n",
    "    let ai_response = format!(\"AI Response to '{}'\", payload.message);\n",
    "\n",
    "    // Store chat history\n",
    "    sqlx::query!(\n",
    "        \"INSERT INTO chats (user_id, message, response) VALUES ($1, $2, $3)\",\n",
    "        user_id,\n",
    "        payload.message,\n",
    "        ai_response\n",
    "    )\n",
    "    .execute(&pool)\n",
    "    .await\n",
    "    .map_err(|_| StatusCode::INTERNAL_SERVER_ERROR)?;\n",
    "\n",
    "    Ok(Json(ChatResponse { response: ai_response }))\n",
    "}\n",
    "\n",
    "🔹 This retrieves the user ID from the request and associates chats with the user.\n",
    "🔹 If an unauthenticated user tries to access /chat, they get 401 Unauthorized.\n",
    "\n",
    "🛠 Step 4: Test the Secured Routes\n",
    "\n",
    "1️⃣ Start the server:\n",
    "\n",
    "cargo run\n",
    "\n",
    "2️⃣ Make an authenticated request (assuming you already registered and got a token):\n",
    "\n",
    "curl -X POST http://127.0.0.1:3000/chat \\\n",
    "     -H \"Content-Type: application/json\" \\\n",
    "     -H \"Authorization: Bearer YOUR_JWT_TOKEN\" \\\n",
    "     -d '{ \"message\": \"Hello AI\" }'\n",
    "\n",
    "💡 If the token is valid, it stores the chat and returns an AI response.\n",
    "\n",
    "3️⃣ Try an unauthenticated request:\n",
    "\n",
    "curl -X POST http://127.0.0.1:3000/chat \\\n",
    "     -H \"Content-Type: application/json\" \\\n",
    "     -d '{ \"message\": \"Hello AI\" }'\n",
    "\n",
    "💡 Should return: 401 Unauthorized.\n",
    "\n",
    "🔜 Next Steps\n",
    "\n",
    "1️⃣ Finalize AI chat processing & connect OpenAI API.\n",
    "2️⃣ Allow AI model selection (OpenAI vs self-hosted).\n",
    "3️⃣ Implement blog post saving & AI-assisted writing.\n",
    "\n",
    "🔥 Our API is now locked down with authentication, and only verified users can chat or store blogs!\n",
    "Ready to build out the AI chat processing next? 🚀"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You’re welcome! Now, let’s build out AI chat processing so users can send messages and get responses from OpenAI (or self-hosted models in the future). 🚀\n",
    "\n",
    "🛠 Step 1: Install Dependencies for AI API Calls\n",
    "\n",
    "We’ll need an HTTP client to interact with OpenAI. Add reqwest and serde_json to Cargo.toml:\n",
    "\n",
    "[dependencies]\n",
    "reqwest = { version = \"0.11\", features = [\"json\"] }\n",
    "serde_json = \"1\"\n",
    "\n",
    "Then, install them:\n",
    "\n",
    "cargo build\n",
    "\n",
    "🛠 Step 2: Add OpenAI API Key to Environment\n",
    "\n",
    "In .env, add:\n",
    "\n",
    "OPENAI_API_KEY=your_openai_api_key_here\n",
    "\n",
    "Make sure to reload environment variables:\n",
    "\n",
    "source .env\n",
    "\n",
    "🛠 Step 3: Implement AI Chat Processing\n",
    "\n",
    "Create a new file src/ai.rs:\n",
    "\n",
    "use reqwest::Client;\n",
    "use serde_json::json;\n",
    "use std::env;\n",
    "\n",
    "pub struct OpenAIClient {\n",
    "    client: Client,\n",
    "    api_key: String,\n",
    "}\n",
    "\n",
    "impl OpenAIClient {\n",
    "    pub fn new() -> Self {\n",
    "        let api_key = env::var(\"OPENAI_API_KEY\").expect(\"OPENAI_API_KEY must be set\");\n",
    "        Self {\n",
    "            client: Client::new(),\n",
    "            api_key,\n",
    "        }\n",
    "    }\n",
    "\n",
    "    pub async fn generate_response(&self, user_input: &str) -> Result<String, reqwest::Error> {\n",
    "        let request_body = json!({\n",
    "            \"model\": \"gpt-4\",  // Can be changed dynamically in the future\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": \"You are an AI assistant.\"},\n",
    "                {\"role\": \"user\", \"content\": user_input}\n",
    "            ],\n",
    "            \"temperature\": 0.7\n",
    "        });\n",
    "\n",
    "        let response = self\n",
    "            .client\n",
    "            .post(\"https://api.openai.com/v1/chat/completions\")\n",
    "            .header(\"Authorization\", format!(\"Bearer {}\", self.api_key))\n",
    "            .header(\"Content-Type\", \"application/json\")\n",
    "            .json(&request_body)\n",
    "            .send()\n",
    "            .await?;\n",
    "\n",
    "        let json_response: serde_json::Value = response.json().await?;\n",
    "        if let Some(text) = json_response[\"choices\"][0][\"message\"][\"content\"].as_str() {\n",
    "            Ok(text.to_string())\n",
    "        } else {\n",
    "            Ok(\"AI failed to respond.\".to_string())\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "🔹 This sends user messages to OpenAI and returns an AI-generated response.\n",
    "🔹 Supports dynamic AI model selection in the future.\n",
    "🔹 Uses reqwest for HTTP calls.\n",
    "\n",
    "🛠 Step 4: Integrate AI Processing into Chat Route\n",
    "\n",
    "Modify src/routes/chat.rs:\n",
    "\n",
    "use axum::{extract::State, http::StatusCode, Json, Extension};\n",
    "use serde::{Deserialize, Serialize};\n",
    "use sqlx::PgPool;\n",
    "use crate::ai::OpenAIClient;\n",
    "\n",
    "#[derive(Deserialize)]\n",
    "struct ChatMessage {\n",
    "    message: String,\n",
    "}\n",
    "\n",
    "#[derive(Serialize)]\n",
    "struct ChatResponse {\n",
    "    response: String,\n",
    "}\n",
    "\n",
    "// Protected chat route\n",
    "async fn chat_handler(\n",
    "    Extension(user_id): Extension<String>,  // Extract user ID from JWT\n",
    "    State(pool): State<PgPool>,\n",
    "    Json(payload): Json<ChatMessage>,\n",
    ") -> Result<Json<ChatResponse>, StatusCode> {\n",
    "    \n",
    "    let ai_client = OpenAIClient::new();\n",
    "    let ai_response = ai_client.generate_response(&payload.message).await\n",
    "        .map_err(|_| StatusCode::INTERNAL_SERVER_ERROR)?;\n",
    "\n",
    "    // Store chat history in database\n",
    "    sqlx::query!(\n",
    "        \"INSERT INTO chats (user_id, message, response) VALUES ($1, $2, $3)\",\n",
    "        user_id,\n",
    "        payload.message,\n",
    "        ai_response\n",
    "    )\n",
    "    .execute(&pool)\n",
    "    .await\n",
    "    .map_err(|_| StatusCode::INTERNAL_SERVER_ERROR)?;\n",
    "\n",
    "    Ok(Json(ChatResponse { response: ai_response }))\n",
    "}\n",
    "\n",
    "// Define chat routes\n",
    "pub fn chat_routes(pool: PgPool) -> Router {\n",
    "    Router::new()\n",
    "        .route(\"/chat\", post(chat_handler))\n",
    "        .with_state(pool)\n",
    "}\n",
    "\n",
    "🔹 This calls OpenAI to generate a response.\n",
    "🔹 Saves conversation history linked to the user in PostgreSQL.\n",
    "🔹 Ensures only authenticated users can chat.\n",
    "\n",
    "🛠 Step 5: Register Chat Route in main.rs\n",
    "\n",
    "Modify src/main.rs to include chat routes:\n",
    "\n",
    "mod auth;\n",
    "mod middleware;\n",
    "mod routes;\n",
    "mod ai;\n",
    "\n",
    "use axum::{Router, routing::get, middleware::from_fn};\n",
    "use sqlx::PgPool;\n",
    "use std::env;\n",
    "use tower_http::cors::{CorsLayer, Any};\n",
    "use routes::{auth::auth_routes, chat::chat_routes};\n",
    "use middleware::auth_middleware;\n",
    "\n",
    "#[tokio::main]\n",
    "async fn main() {\n",
    "    dotenvy::dotenv().ok();\n",
    "\n",
    "    let database_url = env::var(\"DATABASE_URL\").expect(\"DATABASE_URL must be set\");\n",
    "    let pool = PgPool::connect(&database_url).await.expect(\"Failed to connect to database\");\n",
    "\n",
    "    let app = Router::new()\n",
    "        .route(\"/\", get(|| async { \"Welcome to the AI Chat API!\" }))\n",
    "        .merge(auth_routes(pool.clone()))\n",
    "        .merge(chat_routes(pool.clone()))\n",
    "        .route_layer(from_fn(auth_middleware))  // Protect routes\n",
    "        .layer(CorsLayer::new().allow_origin(Any()));\n",
    "\n",
    "    println!(\"🚀 Server running at http://127.0.0.1:3000\");\n",
    "\n",
    "    axum::Server::bind(&\"127.0.0.1:3000\".parse().unwrap())\n",
    "        .serve(app.into_make_service())\n",
    "        .await\n",
    "        .unwrap();\n",
    "}\n",
    "\n",
    "🔹 The chat API is now live and protected by authentication.\n",
    "\n",
    "🛠 Step 6: Test AI Chat Processing\n",
    "\n",
    "1️⃣ Start the server:\n",
    "\n",
    "cargo run\n",
    "\n",
    "2️⃣ Send a chat request with authentication:\n",
    "\n",
    "curl -X POST http://127.0.0.1:3000/chat \\\n",
    "     -H \"Content-Type: application/json\" \\\n",
    "     -H \"Authorization: Bearer YOUR_JWT_TOKEN\" \\\n",
    "     -d '{ \"message\": \"Hello AI!\" }'\n",
    "\n",
    "💡 If successful, the response should be an AI-generated message!\n",
    "\n",
    "🔜 Next Steps\n",
    "\n",
    "1️⃣ Enable AI model selection (OpenAI vs self-hosted models).\n",
    "2️⃣ Improve response time with streaming responses (WebSockets).\n",
    "3️⃣ Optimize query caching (Redis or local memory).\n",
    "4️⃣ Integrate AI-assisted blogging features.\n",
    "\n",
    "🔥 AI chat processing is now fully functional!\n",
    "Would you like to implement model selection next, or refine anything first? 🚀"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome! Now, let’s implement AI model selection so users can choose between OpenAI, Llama 2, or Mistral for their AI responses. This will make our system modular and future-proof. 🚀\n",
    "\n",
    "🛠 Step 1: Update Database to Store User Model Preferences\n",
    "\n",
    "We need to store the user’s preferred AI model so the system remembers their choice.\n",
    "\n",
    "🔹 Modify migrations/init.sql to add a preferred_model column to users:\n",
    "\n",
    "ALTER TABLE users ADD COLUMN preferred_model TEXT DEFAULT 'openai';\n",
    "\n",
    "Apply the migration:\n",
    "\n",
    "sqlx migrate run\n",
    "\n",
    "🔹 Now, the database can store model preferences per user!\n",
    "\n",
    "🛠 Step 2: Create API for Selecting Models\n",
    "\n",
    "We need an API route where users can update their AI model choice.\n",
    "\n",
    "🔹 Modify src/routes/user.rs:\n",
    "\n",
    "use axum::{extract::{State, Extension}, Json, routing::post, Router};\n",
    "use serde::{Deserialize, Serialize};\n",
    "use sqlx::PgPool;\n",
    "use axum::http::StatusCode;\n",
    "\n",
    "#[derive(Deserialize)]\n",
    "struct ModelSelection {\n",
    "    model: String,  // Model choice (e.g., \"openai\", \"llama2\", \"mistral\")\n",
    "}\n",
    "\n",
    "#[derive(Serialize)]\n",
    "struct ModelResponse {\n",
    "    message: String,\n",
    "}\n",
    "\n",
    "// Route to update user's preferred AI model\n",
    "async fn update_model(\n",
    "    Extension(user_id): Extension<String>,\n",
    "    State(pool): State<PgPool>,\n",
    "    Json(payload): Json<ModelSelection>,\n",
    ") -> Result<Json<ModelResponse>, StatusCode> {\n",
    "    \n",
    "    let allowed_models = vec![\"openai\", \"llama2\", \"mistral\"];\n",
    "    \n",
    "    if !allowed_models.contains(&payload.model.as_str()) {\n",
    "        return Err(StatusCode::BAD_REQUEST);\n",
    "    }\n",
    "\n",
    "    let result = sqlx::query!(\n",
    "        \"UPDATE users SET preferred_model = $1 WHERE id = $2\",\n",
    "        payload.model,\n",
    "        user_id\n",
    "    )\n",
    "    .execute(&pool)\n",
    "    .await;\n",
    "\n",
    "    match result {\n",
    "        Ok(_) => Ok(Json(ModelResponse {\n",
    "            message: format!(\"Model updated to {}\", payload.model),\n",
    "        })),\n",
    "        Err(_) => Err(StatusCode::INTERNAL_SERVER_ERROR),\n",
    "    }\n",
    "}\n",
    "\n",
    "// Register user-related routes\n",
    "pub fn user_routes(pool: PgPool) -> Router {\n",
    "    Router::new()\n",
    "        .route(\"/set-model\", post(update_model))\n",
    "        .with_state(pool)\n",
    "}\n",
    "\n",
    "🔹 This allows users to update their AI model preference via /set-model.\n",
    "\n",
    "🛠 Step 3: Modify AI Processing to Use Selected Model\n",
    "\n",
    "Now, we update the AI chat handler to check the user’s preferred model before generating a response.\n",
    "\n",
    "🔹 Modify src/routes/chat.rs:\n",
    "\n",
    "use axum::{extract::State, http::StatusCode, Json, Extension};\n",
    "use serde::{Deserialize, Serialize};\n",
    "use sqlx::PgPool;\n",
    "use crate::ai::{OpenAIClient, SelfHostedClient}; // Import AI clients\n",
    "\n",
    "#[derive(Deserialize)]\n",
    "struct ChatMessage {\n",
    "    message: String,\n",
    "}\n",
    "\n",
    "#[derive(Serialize)]\n",
    "struct ChatResponse {\n",
    "    response: String,\n",
    "}\n",
    "\n",
    "// Chat route that dynamically selects AI model\n",
    "async fn chat_handler(\n",
    "    Extension(user_id): Extension<String>,\n",
    "    State(pool): State<PgPool>,\n",
    "    Json(payload): Json<ChatMessage>,\n",
    ") -> Result<Json<ChatResponse>, StatusCode> {\n",
    "    \n",
    "    // Fetch the user's preferred model\n",
    "    let user_model = sqlx::query!(\n",
    "        \"SELECT preferred_model FROM users WHERE id = $1\",\n",
    "        user_id\n",
    "    )\n",
    "    .fetch_one(&pool)\n",
    "    .await\n",
    "    .map_err(|_| StatusCode::INTERNAL_SERVER_ERROR)?;\n",
    "\n",
    "    let ai_response = match user_model.preferred_model.as_str() {\n",
    "        \"llama2\" | \"mistral\" => {\n",
    "            let self_hosted_client = SelfHostedClient::new(user_model.preferred_model);\n",
    "            self_hosted_client.generate_response(&payload.message).await\n",
    "        },\n",
    "        _ => {\n",
    "            let openai_client = OpenAIClient::new();\n",
    "            openai_client.generate_response(&payload.message).await\n",
    "        }\n",
    "    }\n",
    "    .map_err(|_| StatusCode::INTERNAL_SERVER_ERROR)?;\n",
    "\n",
    "    // Store the chat in the database\n",
    "    sqlx::query!(\n",
    "        \"INSERT INTO chats (user_id, message, response) VALUES ($1, $2, $3)\",\n",
    "        user_id,\n",
    "        payload.message,\n",
    "        ai_response\n",
    "    )\n",
    "    .execute(&pool)\n",
    "    .await\n",
    "    .map_err(|_| StatusCode::INTERNAL_SERVER_ERROR)?;\n",
    "\n",
    "    Ok(Json(ChatResponse { response: ai_response }))\n",
    "}\n",
    "\n",
    "🔹 Now, the chat API dynamically picks the AI model based on user preference.\n",
    "\n",
    "🛠 Step 4: Implement Self-Hosted AI Model Client\n",
    "\n",
    "For now, this is a placeholder for future self-hosted models like Llama 2 or Mistral.\n",
    "\n",
    "🔹 Modify src/ai.rs:\n",
    "\n",
    "use reqwest::Client;\n",
    "use serde_json::json;\n",
    "use std::env;\n",
    "\n",
    "pub struct OpenAIClient {\n",
    "    client: Client,\n",
    "    api_key: String,\n",
    "}\n",
    "\n",
    "impl OpenAIClient {\n",
    "    pub fn new() -> Self {\n",
    "        let api_key = env::var(\"OPENAI_API_KEY\").expect(\"OPENAI_API_KEY must be set\");\n",
    "        Self {\n",
    "            client: Client::new(),\n",
    "            api_key,\n",
    "        }\n",
    "    }\n",
    "\n",
    "    pub async fn generate_response(&self, user_input: &str) -> Result<String, reqwest::Error> {\n",
    "        let request_body = json!({\n",
    "            \"model\": \"gpt-4\",\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": \"You are an AI assistant.\"},\n",
    "                {\"role\": \"user\", \"content\": user_input}\n",
    "            ],\n",
    "            \"temperature\": 0.7\n",
    "        });\n",
    "\n",
    "        let response = self.client\n",
    "            .post(\"https://api.openai.com/v1/chat/completions\")\n",
    "            .header(\"Authorization\", format!(\"Bearer {}\", self.api_key))\n",
    "            .header(\"Content-Type\", \"application/json\")\n",
    "            .json(&request_body)\n",
    "            .send()\n",
    "            .await?;\n",
    "\n",
    "        let json_response: serde_json::Value = response.json().await?;\n",
    "        if let Some(text) = json_response[\"choices\"][0][\"message\"][\"content\"].as_str() {\n",
    "            Ok(text.to_string())\n",
    "        } else {\n",
    "            Ok(\"AI failed to respond.\".to_string())\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "// Placeholder for self-hosted models\n",
    "pub struct SelfHostedClient {\n",
    "    model_name: String,\n",
    "}\n",
    "\n",
    "impl SelfHostedClient {\n",
    "    pub fn new(model_name: String) -> Self {\n",
    "        Self { model_name }\n",
    "    }\n",
    "\n",
    "    pub async fn generate_response(&self, user_input: &str) -> Result<String, String> {\n",
    "        // TODO: Implement local AI model handling\n",
    "        Ok(format!(\n",
    "            \"{} model is currently in development!\",\n",
    "            self.model_name\n",
    "        ))\n",
    "    }\n",
    "}\n",
    "\n",
    "🔹 This makes the AI system modular so we can easily add self-hosted models later.\n",
    "\n",
    "🛠 Step 5: Register New API Routes in main.rs\n",
    "\n",
    "🔹 Modify src/main.rs:\n",
    "\n",
    "mod auth;\n",
    "mod middleware;\n",
    "mod routes;\n",
    "mod ai;\n",
    "\n",
    "use axum::{Router, routing::get, middleware::from_fn};\n",
    "use sqlx::PgPool;\n",
    "use std::env;\n",
    "use tower_http::cors::{CorsLayer, Any};\n",
    "use routes::{auth::auth_routes, chat::chat_routes, user::user_routes};\n",
    "use middleware::auth_middleware;\n",
    "\n",
    "#[tokio::main]\n",
    "async fn main() {\n",
    "    dotenvy::dotenv().ok();\n",
    "\n",
    "    let database_url = env::var(\"DATABASE_URL\").expect(\"DATABASE_URL must be set\");\n",
    "    let pool = PgPool::connect(&database_url).await.expect(\"Failed to connect to database\");\n",
    "\n",
    "    let app = Router::new()\n",
    "        .route(\"/\", get(|| async { \"Welcome to the AI Chat API!\" }))\n",
    "        .merge(auth_routes(pool.clone()))\n",
    "        .merge(chat_routes(pool.clone()))\n",
    "        .merge(user_routes(pool.clone()))  // New route for setting AI models\n",
    "        .route_layer(from_fn(auth_middleware))  \n",
    "        .layer(CorsLayer::new().allow_origin(Any()));\n",
    "\n",
    "    println!(\"🚀 Server running at http://127.0.0.1:3000\");\n",
    "\n",
    "    axum::Server::bind(&\"127.0.0.1:3000\".parse().unwrap())\n",
    "        .serve(app.into_make_service())\n",
    "        .await\n",
    "        .unwrap();\n",
    "}\n",
    "\n",
    "🔜 Next Steps\n",
    "\n",
    "1️⃣ Test model switching with API requests.\n",
    "2️⃣ Implement WebSocket-based streaming for real-time AI responses.\n",
    "3️⃣ Optimize model performance with caching.\n",
    "\n",
    "🔥 AI model selection is now fully functional!\n",
    "Would you like to test it next, or refine anything before moving forward? 🚀"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome! Now, let’s implement WebSocket-based real-time AI response streaming so users get their AI-generated messages word by word instead of waiting for the full response. 🚀\n",
    "\n",
    "🛠 Step 1: Install WebSocket Support in Axum\n",
    "\n",
    "First, we need tokio-tungstenite for WebSocket support. Add this to Cargo.toml:\n",
    "\n",
    "[dependencies]\n",
    "tokio-tungstenite = \"0.20\"\n",
    "futures-util = \"0.3\"\n",
    "\n",
    "Then install it:\n",
    "\n",
    "cargo build\n",
    "\n",
    "🛠 Step 2: Create WebSocket Route for AI Streaming\n",
    "\n",
    "We need to set up a WebSocket connection where AI responses are sent in real-time as they are generated.\n",
    "\n",
    "🔹 Create src/routes/ws.rs:\n",
    "\n",
    "use axum::{\n",
    "    extract::ws::{WebSocket, WebSocketUpgrade, Message},\n",
    "    extract::{State, Extension},\n",
    "    response::IntoResponse,\n",
    "};\n",
    "use futures_util::{StreamExt, SinkExt};\n",
    "use sqlx::PgPool;\n",
    "use crate::ai::OpenAIClient;\n",
    "use std::sync::Arc;\n",
    "use tokio::sync::Mutex;\n",
    "\n",
    "/// WebSocket handler for AI chat streaming\n",
    "pub async fn chat_stream_handler(\n",
    "    ws: WebSocketUpgrade,\n",
    "    Extension(user_id): Extension<String>, // Ensure user is authenticated\n",
    "    State(pool): State<PgPool>,\n",
    ") -> impl IntoResponse {\n",
    "    ws.on_upgrade(|socket| handle_stream(socket, user_id, pool))\n",
    "}\n",
    "\n",
    "async fn handle_stream(socket: WebSocket, user_id: String, pool: PgPool) {\n",
    "    let (mut sender, mut receiver) = socket.split();\n",
    "    let ai_client = Arc::new(Mutex::new(OpenAIClient::new()));\n",
    "\n",
    "    while let Some(Ok(Message::Text(user_input))) = receiver.next().await {\n",
    "        let ai_client_clone = Arc::clone(&ai_client);\n",
    "        let sender_clone = sender.clone();\n",
    "        let user_input_clone = user_input.clone();\n",
    "        let pool_clone = pool.clone();\n",
    "\n",
    "        // Spawn a separate task to handle response streaming\n",
    "        tokio::spawn(async move {\n",
    "            if let Err(_) = stream_ai_response(\n",
    "                sender_clone,\n",
    "                ai_client_clone,\n",
    "                user_id.clone(),\n",
    "                user_input_clone,\n",
    "                pool_clone,\n",
    "            ).await {\n",
    "                println!(\"Error streaming AI response\");\n",
    "            }\n",
    "        });\n",
    "    }\n",
    "}\n",
    "\n",
    "async fn stream_ai_response(\n",
    "    mut sender: futures_util::stream::SplitSink<WebSocket, Message>,\n",
    "    ai_client: Arc<Mutex<OpenAIClient>>,\n",
    "    user_id: String,\n",
    "    user_input: String,\n",
    "    pool: PgPool,\n",
    ") -> Result<(), ()> {\n",
    "    if let Ok(ai_response) = ai_client.lock().await.generate_response(&user_input).await {\n",
    "        let words: Vec<&str> = ai_response.split_whitespace().collect();\n",
    "\n",
    "        for word in words {\n",
    "            if sender.send(Message::Text(word.to_string())).await.is_err() {\n",
    "                return Err(());  // Stop if client disconnects\n",
    "            }\n",
    "            tokio::time::sleep(tokio::time::Duration::from_millis(100)).await; // Simulate typing effect\n",
    "        }\n",
    "\n",
    "        // Save chat to database\n",
    "        let _ = sqlx::query!(\n",
    "            \"INSERT INTO chats (user_id, message, response) VALUES ($1, $2, $3)\",\n",
    "            user_id,\n",
    "            user_input,\n",
    "            ai_response\n",
    "        )\n",
    "        .execute(&pool)\n",
    "        .await;\n",
    "    }\n",
    "\n",
    "    Ok(())\n",
    "}\n",
    "\n",
    "🔹 This creates a WebSocket connection where messages are streamed word-by-word.\n",
    "🔹 Uses tokio tasks to prevent blocking other WebSocket connections.\n",
    "🔹 Stores the full chat history in PostgreSQL after the stream completes.\n",
    "\n",
    "🛠 Step 3: Register WebSocket Route in main.rs\n",
    "\n",
    "Now, we need to register the WebSocket handler in our main router.\n",
    "\n",
    "🔹 Modify src/main.rs:\n",
    "\n",
    "mod auth;\n",
    "mod middleware;\n",
    "mod routes;\n",
    "mod ai;\n",
    "mod ws;\n",
    "\n",
    "use axum::{Router, routing::{get, post}, middleware::from_fn};\n",
    "use sqlx::PgPool;\n",
    "use std::env;\n",
    "use tower_http::cors::{CorsLayer, Any};\n",
    "use routes::{auth::auth_routes, chat::chat_routes, user::user_routes};\n",
    "use ws::chat_stream_handler;\n",
    "use middleware::auth_middleware;\n",
    "\n",
    "#[tokio::main]\n",
    "async fn main() {\n",
    "    dotenvy::dotenv().ok();\n",
    "\n",
    "    let database_url = env::var(\"DATABASE_URL\").expect(\"DATABASE_URL must be set\");\n",
    "    let pool = PgPool::connect(&database_url).await.expect(\"Failed to connect to database\");\n",
    "\n",
    "    let app = Router::new()\n",
    "        .route(\"/\", get(|| async { \"Welcome to the AI Chat API!\" }))\n",
    "        .merge(auth_routes(pool.clone()))\n",
    "        .merge(chat_routes(pool.clone()))\n",
    "        .merge(user_routes(pool.clone()))\n",
    "        .route(\"/ws/chat\", get(chat_stream_handler))\n",
    "        .route_layer(from_fn(auth_middleware))  \n",
    "        .layer(CorsLayer::new().allow_origin(Any()));\n",
    "\n",
    "    println!(\"🚀 Server running at http://127.0.0.1:3000\");\n",
    "\n",
    "    axum::Server::bind(&\"127.0.0.1:3000\".parse().unwrap())\n",
    "        .serve(app.into_make_service())\n",
    "        .await\n",
    "        .unwrap();\n",
    "}\n",
    "\n",
    "🔹 Now /ws/chat is our real-time AI chat endpoint!\n",
    "\n",
    "🛠 Step 4: Test WebSocket Streaming\n",
    "\n",
    "1️⃣ Start the server:\n",
    "\n",
    "cargo run\n",
    "\n",
    "2️⃣ Connect to WebSocket manually using wscat:\n",
    "\n",
    "npm install -g wscat\n",
    "wscat -c ws://127.0.0.1:3000/ws/chat\n",
    "\n",
    "3️⃣ Send a message and receive a real-time AI response:\n",
    "\n",
    "> Hello AI, how are you?\n",
    "< Hello\n",
    "< AI,\n",
    "< how\n",
    "< are\n",
    "< you?\n",
    "\n",
    "💡 The AI response is streamed word by word!\n",
    "\n",
    "🔜 Next Steps\n",
    "\n",
    "1️⃣ Optimize AI streaming speed (adjust token delay dynamically).\n",
    "2️⃣ Enable WebSocket reconnect handling (ensure chat persists if the connection drops).\n",
    "3️⃣ Build a frontend WebSocket chat interface.\n",
    "\n",
    "🔥 We now have real-time AI chat streaming working over WebSockets!\n",
    "Would you like to refine anything before optimizing performance? 🚀"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
